# Import modules
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.svm import SVC
from sklearn.metrics import accuracy_score, classification_report, f1_score, confusion_matrix

# Load iris dataset
iris = load_iris()
X = iris.data
y = iris.target

# Create DataFrame for visualization
dataset = pd.DataFrame(X, columns=iris.feature_names)
dataset['target'] = y

# Know the data
print(dataset.shape)
print(dataset.head())
print(dataset.info())
print(dataset.describe())

# Graphs
dataset.plot(kind='box', subplots=True, layout=(2,3), figsize=(12,6))
plt.suptitle("Boxplot of Features")
plt.show()

dataset.hist(figsize=(10, 6))
plt.suptitle("Histogram of Features")
plt.show()

# Split data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Models
models = []
results = []
models.append(('LR', LogisticRegression(max_iter=200)))
models.append(('SVC', SVC()))
models.append(('DT', DecisionTreeClassifier()))

# Evaluate models using 10-fold CV
for name, model in models:
    kfold = StratifiedKFold(n_splits=10, random_state=1, shuffle=True)
    cv_results = cross_val_score(model, X_train, y_train, cv=kfold, scoring='accuracy')
    results.append(cv_results)
    print(f"{name}: {cv_results.mean():.4f} ({cv_results.std():.4f})")

# Optional: Boxplot comparison
plt.boxplot(results, labels=['LR', 'SVC', 'DT'])
plt.title("Model Accuracy Comparison (10-fold CV)")
plt.ylabel("Accuracy")
plt.show()
